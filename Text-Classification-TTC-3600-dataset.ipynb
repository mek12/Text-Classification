{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/emir/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/emir/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from unicode_tr import unicode_tr\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.tr import Turkish\n",
    "from spacy.lang.tr.stop_words import STOP_WORDS\n",
    "lemmatizer = Turkish().vocab.morphology.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemmas = lemmatizer(word, \"noun\")\n",
    "    lemma = min(lemmas)\n",
    "    return lemma.title() if word.istitle() else lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word):\n",
    "    nlp=Turkish()\n",
    "    remove = \"\"\n",
    "    lexeme = nlp.vocab[word]\n",
    "    if lexeme.is_stop == True:\n",
    "        return remove\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"ve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj\").iterdir()\n",
    "# spor_data = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/spor\").iterdir()\n",
    "# ekonomi_data = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/ekonomi\").iterdir()\n",
    "# teknoloji_data = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/teknoloji\").iterdir()\n",
    "# saglik_data = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/saglik\").iterdir()\n",
    "# siyaset_data = Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/siyaset\").iterdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/spor'), PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/teknoloji'), PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/ekonomi'), PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/saglik'), PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/kultursanat'), PosixPath('/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj/siyaset')]\n"
     ]
    }
   ],
   "source": [
    "print(list(Path(\"/home/emir/MyProjects/DataI_Project/data/TTC-3600_Orj\").iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "data_df = pd.DataFrame()\n",
    "for i in path:\n",
    "    for j in i.iterdir():\n",
    "        data = j.read_text()\n",
    "        data_list.append((str(i).split(\"/\")[-1],data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_list, columns=[\"category\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spor</td>\n",
       "      <td>Mehmet Topal'ın eşinden örnek davranış\\nFenerb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spor</td>\n",
       "      <td>﻿\\n\\tSezonun tamamlanmasının ardından Aytaç Öd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spor</td>\n",
       "      <td>﻿Geride bıraktığımız \\n                sezon \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spor</td>\n",
       "      <td>﻿TRABZON - İbrahim Hacıosmanoğlu, Trabzonspor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spor</td>\n",
       "      <td>Kunter: 'Beşiktaş'ın hedefi şampiyonluk'\\nBeşi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>11 milyon tablet geliyor\\n11 milyon tabletin i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>﻿\\n\\tAynı anda kayıt yaptıran Bakan Kılıç ile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\tHDP H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>AK Parti pankartına CHP tepkisi\\nAdalet ve Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\t2014 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "0        spor  Mehmet Topal'ın eşinden örnek davranış\\nFenerb...\n",
       "1        spor  ﻿\\n\\tSezonun tamamlanmasının ardından Aytaç Öd...\n",
       "2        spor  ﻿Geride bıraktığımız \\n                sezon \\...\n",
       "3        spor  ﻿TRABZON - İbrahim Hacıosmanoğlu, Trabzonspor ...\n",
       "4        spor  Kunter: 'Beşiktaş'ın hedefi şampiyonluk'\\nBeşi...\n",
       "...       ...                                                ...\n",
       "3595  siyaset  11 milyon tablet geliyor\\n11 milyon tabletin i...\n",
       "3596  siyaset  ﻿\\n\\tAynı anda kayıt yaptıran Bakan Kılıç ile ...\n",
       "3597  siyaset  ﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\tHDP H...\n",
       "3598  siyaset  AK Parti pankartına CHP tepkisi\\nAdalet ve Kal...\n",
       "3599  siyaset  ﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\t2014 ...\n",
       "\n",
       "[3600 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spor', 'teknoloji', 'ekonomi', 'saglik', 'kultursanat', 'siyaset'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'spor':0, \n",
    "           'teknoloji':1, \n",
    "           'ekonomi':2, \n",
    "           'saglik':3, \n",
    "           'kultursanat':4, \n",
    "           'siyaset':5\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.insert(1, \"label\",  None, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spor</td>\n",
       "      <td>0</td>\n",
       "      <td>Mehmet Topal'ın eşinden örnek davranış\\nFenerb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spor</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿\\n\\tSezonun tamamlanmasının ardından Aytaç Öd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spor</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿Geride bıraktığımız \\n                sezon \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spor</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿TRABZON - İbrahim Hacıosmanoğlu, Trabzonspor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spor</td>\n",
       "      <td>0</td>\n",
       "      <td>Kunter: 'Beşiktaş'ın hedefi şampiyonluk'\\nBeşi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>5</td>\n",
       "      <td>11 milyon tablet geliyor\\n11 milyon tabletin i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>5</td>\n",
       "      <td>﻿\\n\\tAynı anda kayıt yaptıran Bakan Kılıç ile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>5</td>\n",
       "      <td>﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\tHDP H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>5</td>\n",
       "      <td>AK Parti pankartına CHP tepkisi\\nAdalet ve Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>5</td>\n",
       "      <td>﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\t2014 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category  label                                               text\n",
       "0        spor      0  Mehmet Topal'ın eşinden örnek davranış\\nFenerb...\n",
       "1        spor      0  ﻿\\n\\tSezonun tamamlanmasının ardından Aytaç Öd...\n",
       "2        spor      0  ﻿Geride bıraktığımız \\n                sezon \\...\n",
       "3        spor      0  ﻿TRABZON - İbrahim Hacıosmanoğlu, Trabzonspor ...\n",
       "4        spor      0  Kunter: 'Beşiktaş'ın hedefi şampiyonluk'\\nBeşi...\n",
       "...       ...    ...                                                ...\n",
       "3595  siyaset      5  11 milyon tablet geliyor\\n11 milyon tabletin i...\n",
       "3596  siyaset      5  ﻿\\n\\tAynı anda kayıt yaptıran Bakan Kılıç ile ...\n",
       "3597  siyaset      5  ﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\tHDP H...\n",
       "3598  siyaset      5  AK Parti pankartına CHP tepkisi\\nAdalet ve Kal...\n",
       "3599  siyaset      5  ﻿\\n\\n  \\n    \\n      \\n       \\n     \\n\\t2014 ...\n",
       "\n",
       "[3600 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['label'] = data_df['category'].map(mapping)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "for text in data_df.text:\n",
    "    text = unicode_tr(text).lower()\n",
    "    text = re.sub(r\"[^a-zğüı'şöç]\", \" \", text)\n",
    "    text = nltk.word_tokenize(text)\n",
    "#     text = [remove_stopwords(word) for word in text]\n",
    "    text = [get_lemma(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    text_list.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 15000\n",
    "count_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "count_vectorizer.fit(text_list)\n",
    "sparce_matrix = count_vectorizer.transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data_df.iloc[:,1].values\n",
    "x= sparce_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE MODEL and TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurancy:  0.9277777777777778\n"
     ]
    }
   ],
   "source": [
    "print(\"accurancy: \", nb.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/emir/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "# get accuracy score\n",
    "pred_lr = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(pred_lr, Y_test)\n",
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "    \n",
    "cm_test = confusion_matrix(Y_test, y_pred_test)\n",
    "cm_train = confusion_matrix(Y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8791666666666667, Train Score: 0.9277777777777778\n",
      "\n",
      "CM Test [[141   0   1   1   3   1]\n",
      " [  1  99   4   9   5   1]\n",
      " [  3   4  94   3   7   8]\n",
      " [  0   0   2 103   4   2]\n",
      " [  4   4   2   1 102   4]\n",
      " [  2   1   8   2   0  94]]\n",
      "CM Train [[430   4   6   3   4   6]\n",
      " [  8 435  13  11   9   5]\n",
      " [  8  10 436   5   4  18]\n",
      " [  2   3  12 461   7   4]\n",
      " [  8   8  14   3 442   8]\n",
      " [  4   1   8   8   4 468]]\n"
     ]
    }
   ],
   "source": [
    " acc_test = accuracy_score(Y_test, y_pred_test)\n",
    "acc_train = accuracy_score(Y_train, y_pred_train)\n",
    "print(\"Test Score: {}, Train Score: {}\".format(acc_test, acc_train))\n",
    "print()\n",
    "print(\"CM Test\", cm_test)\n",
    "print(\"CM Train\", cm_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/emir/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 1, 15000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X_train = np.array(X_train).reshape(-1,1)\n",
    "# Y_train = np.array(Y_train).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 1, 15000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 1, 15000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1, 15000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17280,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(30, input_shape=(1,15000)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 1.7271 - accuracy: 0.7229\n",
      "Epoch 2/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 1.3555 - accuracy: 0.9142\n",
      "Epoch 3/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.7785 - accuracy: 0.9618\n",
      "Epoch 4/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.4150 - accuracy: 0.9757\n",
      "Epoch 5/10\n",
      "2880/2880 [==============================] - 3s 1ms/step - loss: 0.2548 - accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "2880/2880 [==============================] - 3s 1ms/step - loss: 0.1667 - accuracy: 0.9910\n",
      "Epoch 7/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.1210 - accuracy: 0.9948\n",
      "Epoch 8/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.0913 - accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.0673 - accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "2880/2880 [==============================] - 4s 1ms/step - loss: 0.0547 - accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "hisory=model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 424us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2145328487786982, 0.9347222447395325]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test new sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [\"Antalya'nın Muratpaşa ilçesinde yaşayan emekli Ahmet Turan Gürel de sunulan kredi avantajından haberdar olduktan sonra gerekli başvuruyu yaptığını dile getirdi.Reklamda 3 bin ile 10 bin lira arasında ihtiyaç kredisi verildiğini görünce mutlu olduğunu aktaran Gürel, şöyle konuştu\",\n",
    "        'Dünyaca ünlü piyanist Fazıl Say, 23 Nisanda Türkiye Büyük Millet Meclisinin (TBMM) kuruluşunun 100. yılı dolayısıyla yaptığı yeni besteyi sosyal medya hesaplarında paylaştı Say, Şükran Türküsü adını verdiği bestesini \"23 Nisan Ulusal Egemenlik ve Çocuk Bayramı kutlu olsun\" notuyla paylaştı.',\n",
    "        'Menajer Ömer Uzun, Mohamed Elnenyin Beşiktaş ta kalıp kalmayacağıyla ilgili, \"Gerek Arsenal tarafında gerek Beşiktaş tarafında salgın sonrasında birtakım şeyler beklemede. Şu ana kadar resmi bir görüşme yapamadık ancak şunu biliyorum ki gerek teknik heyet gerek Beşiktaş, Elnenyi bir sezon daha takımda tutmak istiyor. İşler biraz daha netleştikten sonra da Arsenal ile de oyuncunun gelecek sezon planlamasıyla ilgili birtakım görüşmeler yapılacaktır\" dedi',\n",
    "        \"Yeni tip corona virüs salgını nedeniyle yaşanan ölümlerin sayısı 185 bini aşarken, bilim insanları ve ilaç firmaları küresel salgını durdurmak için birbiriyle yarışıyor. Dünya Sağlık Örgütü (DSÖ), dünya genelinde 83 yeni tip corona virüs (Covid-19), aşısının geliştirildiğini ve bunların altısının insan denemeleri aşamasında olduğunu belirtti.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [unicode_tr(i).lower() for i in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"antalya'nın muratpaşa ilçesinde yaşayan emekli ahmet turan gürel de sunulan kredi avantajından haberdar olduktan sonra gerekli başvuruyu yaptığını dile getirdi.reklamda 3 bin ile 10 bin lira arasında ihtiyaç kredisi verildiğini görünce mutlu olduğunu aktaran gürel, şöyle konuştu\",\n",
       " 'dünyaca ünlü piyanist fazıl say, 23 nisanda türkiye büyük millet meclisinin (tbmm) kuruluşunun 100. yılı dolayısıyla yaptığı yeni besteyi sosyal medya hesaplarında paylaştı say, şükran türküsü adını verdiği bestesini \"23 nisan ulusal egemenlik ve çocuk bayramı kutlu olsun\" notuyla paylaştı.',\n",
       " 'menajer ömer uzun, mohamed elnenyin beşiktaş ta kalıp kalmayacağıyla ilgili, \"gerek arsenal tarafında gerek beşiktaş tarafında salgın sonrasında birtakım şeyler beklemede. şu ana kadar resmi bir görüşme yapamadık ancak şunu biliyorum ki gerek teknik heyet gerek beşiktaş, elnenyi bir sezon daha takımda tutmak istiyor. işler biraz daha netleştikten sonra da arsenal ile de oyuncunun gelecek sezon planlamasıyla ilgili birtakım görüşmeler yapılacaktır\" dedi',\n",
       " 'yeni tip corona virüs salgını nedeniyle yaşanan ölümlerin sayısı 185 bini aşarken, bilim insanları ve ilaç firmaları küresel salgını durdurmak için birbiriyle yarışıyor. dünya sağlık örgütü (dsö), dünya genelinde 83 yeni tip corona virüs (covid-19), aşısının geliştirildiğini ve bunların altısının insan denemeleri aşamasında olduğunu belirtti.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"antalya'nın muratpaşa ilçesinde yaşayan emekli ahmet turan gürel de sunulan kredi avantajından haberdar olduktan sonra gerekli başvuruyu yaptığını dile getirdi reklamda   bin ile    bin lira arasında ihtiyaç kredisi verildiğini görünce mutlu olduğunu aktaran gürel  şöyle konuştu\",\n",
       " 'dünyaca ünlü piyanist fazıl say     nisanda türkiye büyük millet meclisinin  tbmm  kuruluşunun      yılı dolayısıyla yaptığı yeni besteyi sosyal medya hesaplarında paylaştı say  şükran türküsü adını verdiği bestesini     nisan ulusal egemenlik ve çocuk bayramı kutlu olsun  notuyla paylaştı ',\n",
       " 'menajer ömer uzun  mohamed elnenyin beşiktaş ta kalıp kalmayacağıyla ilgili   gerek arsenal tarafında gerek beşiktaş tarafında salgın sonrasında birtakım şeyler beklemede  şu ana kadar resmi bir görüşme yapamadık ancak şunu biliyorum ki gerek teknik heyet gerek beşiktaş  elnenyi bir sezon daha takımda tutmak istiyor  işler biraz daha netleştikten sonra da arsenal ile de oyuncunun gelecek sezon planlamasıyla ilgili birtakım görüşmeler yapılacaktır  dedi',\n",
       " 'yeni tip corona virüs salgını nedeniyle yaşanan ölümlerin sayısı     bini aşarken  bilim insanları ve ilaç firmaları küresel salgını durdurmak için birbiriyle yarışıyor  dünya sağlık örgütü  dsö   dünya genelinde    yeni tip corona virüs  covid      aşısının geliştirildiğini ve bunların altısının insan denemeleri aşamasında olduğunu belirtti ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = [re.sub(r\"[^a-zğüı'şöç]\", \" \", i) for i in text1]\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=count_vectorizer.transform(text1)\n",
    "text1=text1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 15000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = list(mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekonomi\n",
      "kultursanat\n",
      "spor\n",
      "saglik\n"
     ]
    }
   ],
   "source": [
    "for j in predictions:\n",
    "    pred = mapping_list[j]\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
